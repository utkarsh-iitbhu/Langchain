{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face x LangChain : A new partner package in LangChain\n",
    "langchain_huggingface, a partner package in LangChain jointly maintained by Hugging Face and LangChain. This new Python package is designed to bring the power of the latest development of Hugging Face into LangChain and keep it up to date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## API Call\n",
    "# %pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFaceEndpoint\n",
    "#### How to Access HuggingFace Models with API\n",
    "There are also two ways to use this class. You can specify the model with the repo_id parameter. Those endpoints use the serverless API, which is particularly beneficial to people using pro accounts or enterprise hub. Still, regular users can already have access to a fair amount of request by connecting with their HF token in the environment where they are executing the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, model_kwargs={'max_length': 150}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\win10\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, model_kwargs={'max_length': 150, 'token': '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'}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nMachine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves.\\n\\nThe process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust actions accordingly.\\n\\nMachine learning is a popular approach to artificial intelligence because it can find patterns in large amounts of data and make decisions with minimal human intervention. It is used in a wide variety of applications, including email filtering, detection of network intruders, and computer vision, where it is used to identify objects, people, and scenes in images.\\n\\nTypes of Machine Learning\\n\\nMachine learning can be broadly categorized into three types: supervised learning, unsupervised learning, and reinforcement learning.\\n\\n1. Supervised learning: In supervised learning, the algorithm is trained on a labeled dataset. The algorithm learns to map input data to an output label by minimizing the difference between its predicted output and the actual output. The goal is to learn a function that maps inputs to the correct outputs, so that when the algorithm is given new inputs, it can predict the correct output.\\n\\nExamples of supervised learning algorithms include linear regression, logistic regression, decision trees, and support vector machines (SVM).\\n\\n2. Unsupervised learning: In unsupervised learning, the algorithm is trained on an unlabeled dataset. The goal is to find patterns or structure in the data without any predefined labels. Unsupervised learning algorithms are used for tasks such as clustering, dimensionality reduction, and anomaly detection.\\n\\nExamples of unsupervised learning algorithms include k-means clustering, principal component analysis (PCA), and autoencoders.\\n\\n3. Reinforcement learning: In reinforcement learning, the algorithm learns to make decisions by interacting with an environment and receiving feedback in the form of rewards or punishments. The goal is to learn a policy that maximizes the cumulative reward over time.\\n\\nReinforcement learning is used in applications such as game playing, robotics, and autonomous driving'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" and how does it work?\\n\\nGenerative AI is a type of artificial intelligence that can create new content, such as text, images, music, or even 3D models, based on the data it has been trained on. It works by learning patterns and structures from large datasets, and then using those patterns to generate new content that is similar to the original data.\\n\\nThere are several techniques used in generative AI, but one of the most common is called deep learning, which involves using artificial neural networks to analyze and generate data. The neural network consists of interconnected layers of nodes, each of which processes a specific aspect of the data. The network is trained on a large dataset, and during training, the weights of the connections between the nodes are adjusted to minimize the difference between the network's output and the desired output.\\n\\nOnce the network has been trained, it can be used to generate new content by providing it with a random input and allowing it to generate an output based on the patterns it has learned. The output can then be refined and improved through further training or by using techniques such as reinforcement learning, which involves rewarding the network for producing outputs that are more similar to the desired output.\\n\\nGenerative AI has a wide range of applications, from creating realistic images and videos for use in movies and video games, to generating text for chatbots and other applications, to creating music and even writing articles and books. It is also being used in fields such as medicine and materials science to generate new drugs and materials with specific properties.\\n\\nGenerative AI is a rapidly evolving field, and there are many exciting developments on the horizon. As the technology continues to improve, we can expect to see even more creative and innovative uses of generative AI in the years to come.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is generative AI \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='google/gemma-2-9b', temperature=0.7, model_kwargs={'max_length': 150}, model='google/gemma-2-9b', client=<InferenceClient(model='google/gemma-2-9b', timeout=120)>, async_client=<InferenceClient(model='google/gemma-2-9b', timeout=120)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"google/gemma-2-9b\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\win10\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='google/gemma-2-9b', temperature=0.7, model_kwargs={'max_length': 150, 'token': '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'}, model='google/gemma-2-9b', client=<InferenceClient(model='google/gemma-2-9b', timeout=120)>, async_client=<InferenceClient(model='google/gemma-2-9b', timeout=120)>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"google/gemma-2-9b\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] template='\\nQuestion:{question}\\nAnswer:Lets think step by step.\\n'\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate,LLMChain\n",
    "template=\"\"\"\n",
    "Question:{question}\n",
    "Answer:Lets think step by step.\n",
    "\"\"\"\n",
    "prompt=PromptTemplate(template=template,input_variables=[\"question\"])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "u:\\Langchain-repo\\.genai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'? India won the cricket World cup 2011 by defeating Sri Lanka in the final match. India scored 277 runs in 49.5 overs with the loss of 8 wickets and restricted Sri Lanka to 274 runs in 50 overs.\\n\\n## Who won the Cricket World Cup in 2011?\\n\\nIndia won the 2011 Cricket World Cup, defeating Sri Lanka by six wickets in the final. The tournament was held in India, Sri Lanka and Bangladesh from 19 February to 2 April 2011.\\n\\n## Who won the cricket World Cup 2015?\\n\\nAustralia won the 2015 Cricket World Cup, defeating New Zealand by seven wickets in the final. The tournament was held in Australia and New Zealand from 14 February to 29 March 2015.\\n\\n## Who won the cricket World Cup 2007?\\n\\nAustralia won the 2007 Cricket World Cup, defeating Sri Lanka by 53 runs in the final. The tournament was held in the West Indies from 13 March to 28 April 2007.\\n\\n## Who won the cricket World Cup 2019?\\n\\nEngland won the 2019 Cricket World Cup, defeating New Zealand by 1 run in a super over (a tie-breaker) in the final. The tournament was held in England and Wales from 30 May to 14 July 2019.\\n\\n## Who won the cricket World Cup 2003?\\n\\nAustralia won the 2003 Cricket World Cup, defeating India by 125 runs in the final. The tournament was held in South Africa from 23 February to 23 March 2003.\\n\\n## Who won the cricket World Cup 1999?\\n\\nAustralia won the 1999 Cricket World Cup, defeating Pakistan by 8 wickets in the final. The tournament was held in England from 10 May to 20 June 1999.\\n\\n## Who won the cricket World Cup 1996?\\n\\nSri Lanka won the 1996'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
    "llm.invoke(\"Who won the cricket World cup 2011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "u:\\Langchain-repo\\.genai\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\utkar\\.cache\\huggingface\\hub\\models--BAAI--bge-small-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = hf.embed_query(\"hi this is harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.028416577726602554,\n",
       " 0.0121832937002182,\n",
       " 0.027443960309028625,\n",
       " -0.0548286959528923,\n",
       " 0.02423892170190811,\n",
       " 0.0007662929128855467,\n",
       " 0.06783363968133926,\n",
       " 0.01634833589196205,\n",
       " -0.01895076222717762,\n",
       " 0.012542912736535072,\n",
       " 0.021564992144703865,\n",
       " -0.08793038874864578,\n",
       " 0.000646064174361527,\n",
       " 0.033270809799432755,\n",
       " 0.005463752895593643,\n",
       " -0.060376428067684174,\n",
       " 0.05042264237999916,\n",
       " 0.004434806294739246,\n",
       " 0.000959866214543581,\n",
       " 0.0017405693652108312,\n",
       " 0.003298821160569787,\n",
       " 0.03167249262332916,\n",
       " -0.04880749061703682,\n",
       " -0.04481916502118111,\n",
       " 0.07132109254598618,\n",
       " -0.007510842755436897,\n",
       " -0.001125918934121728,\n",
       " -0.015801191329956055,\n",
       " -0.029402393847703934,\n",
       " -0.17224562168121338,\n",
       " -0.03189520537853241,\n",
       " -0.0016291375504806638,\n",
       " 0.018104983493685722,\n",
       " 0.01531539112329483,\n",
       " -0.02072959765791893,\n",
       " -0.008872960694134235,\n",
       " -0.0012822785647585988,\n",
       " 0.027276884764432907,\n",
       " -0.010114241391420364,\n",
       " 0.012621629051864147,\n",
       " -0.00707787973806262,\n",
       " -0.016693171113729477,\n",
       " 0.040855854749679565,\n",
       " 0.023938339203596115,\n",
       " -0.0200815387070179,\n",
       " 0.028681160882115364,\n",
       " -0.019400732591748238,\n",
       " -0.014618197456002235,\n",
       " 0.017379600554704666,\n",
       " 0.004164086189121008,\n",
       " 0.06415652483701706,\n",
       " 0.047683052718639374,\n",
       " 0.0018365151481702924,\n",
       " -8.070441253948957e-05,\n",
       " 0.016596786677837372,\n",
       " 0.011124184355139732,\n",
       " 0.069694384932518,\n",
       " 0.05182050168514252,\n",
       " 0.055685289204120636,\n",
       " 0.05551542714238167,\n",
       " 0.0005039370735175908,\n",
       " 0.04187057167291641,\n",
       " -0.15344087779521942,\n",
       " 0.05180780217051506,\n",
       " 0.006689781788736582,\n",
       " -0.03167073428630829,\n",
       " -0.0091050174087286,\n",
       " -0.05160469189286232,\n",
       " 0.04250858351588249,\n",
       " 0.028200063854455948,\n",
       " -0.010748092085123062,\n",
       " 0.02240578457713127,\n",
       " 0.04439550265669823,\n",
       " 0.0041155144572257996,\n",
       " 0.018998464569449425,\n",
       " -0.004357197787612677,\n",
       " 0.04762762784957886,\n",
       " 0.011824633926153183,\n",
       " 0.008164606988430023,\n",
       " 0.008177285082638264,\n",
       " -0.009698749519884586,\n",
       " -0.01426028087735176,\n",
       " 0.011409701779484749,\n",
       " -0.07362118363380432,\n",
       " -0.05439525470137596,\n",
       " -0.057039644569158554,\n",
       " -0.0036085518077015877,\n",
       " 0.0026660833973437548,\n",
       " 0.023782474920153618,\n",
       " 0.015376217663288116,\n",
       " -0.07020370662212372,\n",
       " -0.03130036219954491,\n",
       " -0.0031142933294177055,\n",
       " -0.01581217534840107,\n",
       " -0.037913981825113297,\n",
       " -0.025921940803527832,\n",
       " 0.01816842332482338,\n",
       " -0.03882460668683052,\n",
       " -0.05674507096409798,\n",
       " 0.5792059898376465,\n",
       " -0.05278833955526352,\n",
       " 0.020716393366456032,\n",
       " 0.06794394552707672,\n",
       " -0.04541650786995888,\n",
       " 0.01164248026907444,\n",
       " -0.021571772173047066,\n",
       " 0.020341727882623672,\n",
       " -0.027448952198028564,\n",
       " -0.04558897390961647,\n",
       " -0.029443558305501938,\n",
       " -0.023662513121962547,\n",
       " -0.03431524708867073,\n",
       " 0.0019388369983062148,\n",
       " -0.07095140218734741,\n",
       " 0.03455633670091629,\n",
       " -0.030558953061699867,\n",
       " 0.039078596979379654,\n",
       " -0.029707306995987892,\n",
       " -0.000828292453661561,\n",
       " -0.012159368954598904,\n",
       " -0.01827283576130867,\n",
       " 0.02548653818666935,\n",
       " -0.0044616591185331345,\n",
       " 0.01633533276617527,\n",
       " 0.01912647858262062,\n",
       " -0.054832056164741516,\n",
       " 0.027635997161269188,\n",
       " -0.004757656715810299,\n",
       " 0.05900171399116516,\n",
       " -0.0016944739036262035,\n",
       " 0.008015012368559837,\n",
       " -0.037726834416389465,\n",
       " -0.09893043339252472,\n",
       " -0.022574400529265404,\n",
       " -0.0376046784222126,\n",
       " -0.0021698575001209974,\n",
       " 0.00324460887350142,\n",
       " -0.019202517345547676,\n",
       " -0.00863123033195734,\n",
       " -0.04802309721708298,\n",
       " 0.008696725592017174,\n",
       " -0.09516109526157379,\n",
       " -0.03496045991778374,\n",
       " -0.04360799863934517,\n",
       " -0.0003439880965743214,\n",
       " -0.010173643007874489,\n",
       " -0.03099953383207321,\n",
       " 0.024309679865837097,\n",
       " -0.02040204033255577,\n",
       " 0.03113938868045807,\n",
       " 0.0008811048464849591,\n",
       " 0.013916493393480778,\n",
       " -0.031196171417832375,\n",
       " -0.03715401515364647,\n",
       " 0.004029599949717522,\n",
       " 0.014799789525568485,\n",
       " 0.043188948184251785,\n",
       " 0.03875482454895973,\n",
       " 0.013852021656930447,\n",
       " 0.019797878339886665,\n",
       " 0.010267085395753384,\n",
       " -0.005434093065559864,\n",
       " -0.014299211092293262,\n",
       " 0.027637843042612076,\n",
       " 0.00980264600366354,\n",
       " -0.13550283014774323,\n",
       " -0.01713976263999939,\n",
       " 0.01761712320148945,\n",
       " 0.023132257163524628,\n",
       " 0.0017589956987649202,\n",
       " 0.030889388173818588,\n",
       " 0.039918698370456696,\n",
       " -0.01368417963385582,\n",
       " 0.024816513061523438,\n",
       " 0.05405019223690033,\n",
       " 0.017761152237653732,\n",
       " -0.01847505383193493,\n",
       " 0.02595539391040802,\n",
       " -0.006377524230629206,\n",
       " -0.016587315127253532,\n",
       " 0.03784799203276634,\n",
       " -0.02729004994034767,\n",
       " -0.0528457909822464,\n",
       " -0.03803319111466408,\n",
       " 0.05191105976700783,\n",
       " -0.00755706150084734,\n",
       " -0.03180530294775963,\n",
       " 0.013284161686897278,\n",
       " -0.027723729610443115,\n",
       " 0.05630652233958244,\n",
       " 0.0030419069807976484,\n",
       " 0.053324826061725616,\n",
       " -0.05791128799319267,\n",
       " -0.01132582500576973,\n",
       " -0.031172020360827446,\n",
       " 0.025608690455555916,\n",
       " 0.03389059007167816,\n",
       " -0.0010284362360835075,\n",
       " 0.01586487889289856,\n",
       " 0.010595203377306461,\n",
       " -0.02703777514398098,\n",
       " -0.0009308057487942278,\n",
       " -0.04815223813056946,\n",
       " 0.028179215267300606,\n",
       " 0.010320612229406834,\n",
       " 0.06662961840629578,\n",
       " -0.016558213159441948,\n",
       " -0.0044313715770840645,\n",
       " 0.038234248757362366,\n",
       " -0.023408200591802597,\n",
       " -0.035581763833761215,\n",
       " -0.05829072371125221,\n",
       " -0.011181513778865337,\n",
       " -0.01768459938466549,\n",
       " -0.016141284257173538,\n",
       " -0.0342453308403492,\n",
       " -0.025139551609754562,\n",
       " 0.039396677166223526,\n",
       " -0.02365819178521633,\n",
       " -0.00772502738982439,\n",
       " -0.005098931957036257,\n",
       " -0.03523433953523636,\n",
       " -0.0140768401324749,\n",
       " -0.22326026856899261,\n",
       " -0.0314713716506958,\n",
       " -0.0012906118063256145,\n",
       " -0.0017200072761625051,\n",
       " -0.007846061140298843,\n",
       " -0.05802324414253235,\n",
       " 0.046174533665180206,\n",
       " 0.02455265074968338,\n",
       " 0.07320843636989594,\n",
       " 0.0172683484852314,\n",
       " 0.04761207848787308,\n",
       " 0.013473342172801495,\n",
       " -0.0055160438641905785,\n",
       " -0.014357826672494411,\n",
       " -0.009674303233623505,\n",
       " 0.04878251627087593,\n",
       " 0.03053814172744751,\n",
       " -0.024993952363729477,\n",
       " 0.021486228331923485,\n",
       " 0.01763981021940708,\n",
       " 0.05313890054821968,\n",
       " 0.013484988361597061,\n",
       " -0.023225998505949974,\n",
       " -0.021403959020972252,\n",
       " 0.026075351983308792,\n",
       " 0.00202918634749949,\n",
       " 0.12753742933273315,\n",
       " 0.08316836506128311,\n",
       " 0.04408947378396988,\n",
       " -0.02670358121395111,\n",
       " 0.005522017367184162,\n",
       " -0.009294897317886353,\n",
       " 0.02007428929209709,\n",
       " -0.09684177488088608,\n",
       " -0.02470393478870392,\n",
       " 0.025086969137191772,\n",
       " 0.0020886072888970375,\n",
       " -0.0448940210044384,\n",
       " -0.07861137390136719,\n",
       " -0.004376319237053394,\n",
       " -0.06590455025434494,\n",
       " 0.014689394272863865,\n",
       " -0.057641856372356415,\n",
       " -0.07152026891708374,\n",
       " -0.062326524406671524,\n",
       " 0.003431656863540411,\n",
       " -0.046065494418144226,\n",
       " 0.04530087485909462,\n",
       " -0.02676227129995823,\n",
       " 0.034010931849479675,\n",
       " 0.045473791658878326,\n",
       " -0.02817923203110695,\n",
       " 0.0050118048675358295,\n",
       " 0.009630800224840641,\n",
       " -0.030305584892630577,\n",
       " -0.03612479567527771,\n",
       " -0.013626961968839169,\n",
       " -0.032653745263814926,\n",
       " -0.04467751830816269,\n",
       " 0.010642197914421558,\n",
       " -0.027486339211463928,\n",
       " -0.02456512302160263,\n",
       " -0.024747785180807114,\n",
       " 0.053619589656591415,\n",
       " 0.02078995108604431,\n",
       " 0.019468482583761215,\n",
       " 0.05324118211865425,\n",
       " -0.014002462849020958,\n",
       " 0.021243276074528694,\n",
       " -0.04957323521375656,\n",
       " -0.008522599004209042,\n",
       " 0.007852854207158089,\n",
       " -0.05719393119215965,\n",
       " -0.027550632134079933,\n",
       " 0.0053008971735835075,\n",
       " 0.040072910487651825,\n",
       " 0.019597917795181274,\n",
       " -0.04519732668995857,\n",
       " 0.032435860484838486,\n",
       " -0.012342395260930061,\n",
       " 0.03431444242596626,\n",
       " 0.021102098748087883,\n",
       " 0.03984647989273071,\n",
       " 0.031663794070482254,\n",
       " -0.03359024226665497,\n",
       " 0.03164784610271454,\n",
       " -0.0033045224845409393,\n",
       " 0.004641836509108543,\n",
       " 0.03758935630321503,\n",
       " -0.059244561940431595,\n",
       " 0.0070283482782542706,\n",
       " 0.0038087074644863605,\n",
       " -0.025788886472582817,\n",
       " -0.021203355863690376,\n",
       " 0.022691210731863976,\n",
       " -0.021772975102066994,\n",
       " -0.27963775396347046,\n",
       " 0.007267427630722523,\n",
       " 0.021072033792734146,\n",
       " 0.04519744589924812,\n",
       " -0.02053450047969818,\n",
       " 0.024313705042004585,\n",
       " -0.0006136919255368412,\n",
       " -0.01185704581439495,\n",
       " -0.03296775370836258,\n",
       " 0.0358431376516819,\n",
       " 0.0312817320227623,\n",
       " 0.06373953819274902,\n",
       " 0.04654785618185997,\n",
       " -0.014470534399151802,\n",
       " 0.015869760885834694,\n",
       " 0.03397127613425255,\n",
       " 0.01805954799056053,\n",
       " 0.0022987385746091604,\n",
       " 0.016549894586205482,\n",
       " -0.021714890375733376,\n",
       " -0.034860026091337204,\n",
       " -0.0008649183437228203,\n",
       " 0.15126042068004608,\n",
       " -0.024536747485399246,\n",
       " 0.030671197921037674,\n",
       " -0.007318207994103432,\n",
       " -0.006135452538728714,\n",
       " 0.06415145099163055,\n",
       " 0.01602148450911045,\n",
       " -0.036364421248435974,\n",
       " 0.019898615777492523,\n",
       " -0.021172357723116875,\n",
       " 0.048294130712747574,\n",
       " -0.044780973345041275,\n",
       " 0.04763384908437729,\n",
       " 0.0007749142241664231,\n",
       " -0.005927966441959143,\n",
       " 0.06154269725084305,\n",
       " 0.023968396708369255,\n",
       " 0.013305019587278366,\n",
       " 0.022684480994939804,\n",
       " 0.01453806459903717,\n",
       " -0.05215906351804733,\n",
       " -0.032749660313129425,\n",
       " 0.08583343774080276,\n",
       " -0.003724808804690838,\n",
       " 0.0013493997976183891,\n",
       " 0.040919896215200424,\n",
       " 0.011659680865705013,\n",
       " 0.058436207473278046,\n",
       " -0.022286158055067062,\n",
       " -0.011520679108798504,\n",
       " 0.0047057014890015125,\n",
       " 0.047182630747556686,\n",
       " -0.0019179136725142598,\n",
       " 0.033009350299835205,\n",
       " -0.03505055233836174,\n",
       " -0.020736558362841606,\n",
       " -0.009222153574228287,\n",
       " 0.014618262648582458,\n",
       " 0.006456063594669104,\n",
       " 0.0010978342033922672,\n",
       " 0.01022400427609682,\n",
       " 0.08537212014198303,\n",
       " 0.03883953019976616]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
